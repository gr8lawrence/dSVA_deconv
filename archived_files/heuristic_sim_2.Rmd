---
title: "Simulation 2"
author: "Tianyi Liu"
date: "2023-07-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE, fig.align = 'center')
options(scipen = 1, digits = 3)
```

```{r packages, echo=TRUE}
# source("a01_extended_dSVA.R")
source("s02_simulation_functions.R")
library(extraDistr)
library(statmod)
library(MASS)
library(dplyr)
library(tidyr)
library(statmod)
set.seed(100)
```

We aim at finding a simulation parameter setting where latent variables can carry significant variations as compared to that carried by the regression parameters, such that using dSVA can prove to be beneficial.

$$
\mathbf{Y} = \mathbf{\Theta}\mathbf{P} + \mathbf{Z}\mathbf{D} + \mathbf{E}, \\
\mathbf{P} \geq 0, \\
\mathbf{P}^T \mathbf{1} = \mathbf{1}.
$$
  * $n$: number of samples;
  * $m$: number of genes ($m >> n$);
  * $K$: number of cell types;
  * $\lambda$: controls the gene expression cell-type specificity;
  * $\mu$: control the size of the second and third latent parameters;
  * $\sigma$: control the variance of latent parameters;

Create an error-free model $\mathbf{E} = \mathbf{0}$ first:

  * $\mathbf{x}_j^T \sim \pi(W \cdot {\rm dir}(1, 1, \dots, 1) + (1 - W) \cdot {\rm dir}(\lambda, 1, \dots, 1) )$, $W \sim Ber(p_{\rm sig})$, and $\pi$ is a sampling operator;
  * $\mathbf{p}_i \sim {\rm dir}(\alpha_{i1}, \dots, \alpha_{iK})$;
  * $\mathbf{d}^T_1 = (0, \dots. 0, 1, \dots, 1)^T$ ($n/2$ $0$s and $1$s each).
  * $\mathbf{d}^T_2 = (0, \dots. 0, 1, \dots, 1, 0, \dots. 0, 1, \dots, 1)^T$ ($n/4$ $0$s and $1$s each).
  * $\mathbf{d}^T_3 = \mathbf{1} - \mathbf{d}^T_2$.
  * $z_{1j} \sim N(0, \sigma^2/K^4)$.
  * $z_{2j} \sim N(-\mu/K^2, \sigma^2/K^4)$.
  * $z_{3j} \sim N(\mu/K^2, \sigma^2/K^4)$.

```{}
  D[1, ] <- c(rep(0, floor(n/2)), rep(1, ceiling(n/2)))
  D[2, ] <- rep(c(rep(0, floor(n/4)), rep(1, ceiling(n/4))), 2)
  D[3, ] <- 1 - D[2, ]
  Z[, 1] <- rnorm(m, 0, sigma/K^2)
  Z[, 2] <- rnorm(m, -mu/K^2, sigma/K^2)
  Z[, 3] <- rnorm(m, mu/K^2, sigma/K^2)
```

```{r sim_param}
n <- 20
m <- 2000
K <- 5
p <- 3
p_sig <- 0.5
lambda <- 3
mu_seq <- seq(0, 9, 3)
sigma <- 4
```

```{r simulation_code, echo = FALSE}
B <- 100
result_matrix <- matrix(nrow = B, ncol = 6)
par(mfrow = c(2, length(mu_seq)))
for (mu in mu_seq) {
  ## run the simulation B times
  for (b in 1:B) {
    true_data <- dSVA_model_sim(m, n, K, p, p_sig, lambda, mu)
    
    ## NNLS
    P_nnls <- apply(true_data$Y, 2, function(y) {lsei::nnls(a = true_data$X, b = y)$x})
    P_nnls <- apply(P_nnls, 2, function(x) x/sum(x))
    
    ## constrained NNLS
    P_pnnls <- apply(true_data$Y, 2, function(y) {lsei::pnnls(a = true_data$X, b = y, sum = 1)$x})
    
    ## if we know both X and Z
    # X_new <- cbind(true_data$Z, true_data$X)
    # P_hat <- apply(true_data$Y, 2, function(y) {lsei::pnnls(a = X_new, b = y, k = p, sum = 1)$x})[-seq(p), ]
    # 
    P_hat <- apply(true_data$Y - true_data$Z %*% true_data$D, 2, function(y) {lsei::pnnls(a = true_data$X, b = y , sum = 1)$x})
    
    ## mean sample-wise correlations
    cor_nnls <- mean(my_cor(true_data$P_star, P_nnls))
    cor_pnnls <- mean(my_cor(true_data$P_star, P_pnnls))
    cor_best <- mean(my_cor(true_data$P_star, P_hat))
    
    ## mean squared errors
    mse_nnls <- my_mse(true_data$P_star, P_nnls)
    mse_pnnls <- my_mse(true_data$P_star, P_pnnls)
    mse_best <- my_mse(true_data$P_star, P_hat)
    
    result_matrix[b, ] <- c(cor_nnls, cor_pnnls, cor_best, mse_nnls, mse_pnnls, mse_best)
  }
  result_df <- as_tibble(cbind(1:B, result_matrix))
  colnames(result_df) <- c("b", "cor_nnls", "cor_pnnls", "cor_known", "mse_nnls", "mse_pnnls", "mse_known")
  boxplot(result_df$cor_nnls, result_df$cor_pnnls, result_df$cor_known, xlab = "Method", ylab = "Cor", main = paste("Mu =", mu, "Sigma =", sigma))
  axis(1, at = c("1", "2", "3"), labels = c("NNLS", "PNNLS", "Known"))
  boxplot(result_df$mse_nnls, result_df$mse_pnnls, result_df$mse_known, xlab = "Method", ylab = "MSE", main = paste("Mu =", mu, "Sigma =", sigma))
  axis(1, at = c("1", "2", "3"), labels = c("NNLS", "PNNLS", "Known"))
}
```

```{r sim_param_var}
n <- 20
m <- 2000
K <- 5
p <- 3
p_sig <- 0.5
lambda <- 3
mu <- 5
sigma_seq <- seq(3, 12, 3)
```

```{r simulation_code_var, echo = FALSE}
B <- 100
result_matrix <- matrix(nrow = B, ncol = 6)
par(mfrow = c(2, length(mu_seq)))
for (sigma in sigma_seq) {
  ## run the simulation B times
  for (b in 1:B) {
    true_data <- dSVA_model_sim(m, n, K, p, p_sig, lambda, mu, sigma)
    
    ## NNLS
    P_nnls <- apply(true_data$Y, 2, function(y) {lsei::nnls(a = true_data$X, b = y)$x})
    P_nnls <- apply(P_nnls, 2, function(x) x/sum(x))
    
    ## constrained NNLS
    P_pnnls <- apply(true_data$Y, 2, function(y) {lsei::pnnls(a = true_data$X, b = y, sum = 1)$x})
    
    ## if we know both X and Z
    # X_new <- cbind(true_data$Z, true_data$X)
    # P_hat <- apply(true_data$Y, 2, function(y) {lsei::pnnls(a = X_new, b = y, k = p, sum = 1)$x})[-seq(p), ]
    # 
    P_hat <- apply(true_data$Y - true_data$Z %*% true_data$D, 2, function(y) {lsei::pnnls(a = true_data$X, b = y , sum = 1)$x})
    
    ## mean sample-wise correlations
    cor_nnls <- mean(my_cor(true_data$P_star, P_nnls))
    cor_pnnls <- mean(my_cor(true_data$P_star, P_pnnls))
    cor_best <- mean(my_cor(true_data$P_star, P_hat))
    
    ## mean squared errors
    mse_nnls <- my_mse(true_data$P_star, P_nnls)
    mse_pnnls <- my_mse(true_data$P_star, P_pnnls)
    mse_best <- my_mse(true_data$P_star, P_hat)
    
    result_matrix[b, ] <- c(cor_nnls, cor_pnnls, cor_best, mse_nnls, mse_pnnls, mse_best)
  }
  result_df <- as_tibble(cbind(1:B, result_matrix))
  colnames(result_df) <- c("b", "cor_nnls", "cor_pnnls", "cor_known", "mse_nnls", "mse_pnnls", "mse_known")
  boxplot(result_df$cor_nnls, result_df$cor_pnnls, result_df$cor_known, xlab = "Method", ylab = "Cor", main = paste("Mu =", mu, "Sigma =", sigma))
  axis(1, at = c("1", "2", "3"), labels = c("NNLS", "PNNLS", "Known"))
  boxplot(result_df$mse_nnls, result_df$mse_pnnls, result_df$mse_known, xlab = "Method", ylab = "MSE", main = paste("Mu =", mu, "Sigma =", sigma))
  axis(1, at = c("1", "2", "3"), labels = c("NNLS", "PNNLS", "Known"))
}
```
